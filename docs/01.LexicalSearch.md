# Overview

OpenSearch의 Lexical Search는 사용자가 데이터셋 내에서 특정 단어나 구문을 검색할 수 있게 해주는 기능입니다. 이는 텍스트를 검색 가능한 토큰으로 변환하는 어휘 색인 방식을 사용합니다. 이 방법은 대량의 텍스트 데이터를 검색하는 데 특히 유용하며 데이터 내에서 특정 단어, 구문, 또는 패턴을 식별하는 데 사용할 수 있습니다.

# 인덱스 생성

## 데이터셋

이 워크샵에서는 코드와 함께 제공된 영화 정보 데이터셋을 사용합니다.

# 데이터 인제스트

이 코드는 Python의 시스템 경로(system path)에 특정 디렉토리를 추가하는 역할을 합니다.

1. `import sys`는 Python의 내장 모듈인 `sys`를 임포트합니다. `sys` 모듈은 Python 인터프리터와 관련된 다양한 기능을 제공합니다.
2. `sys.path`는 Python 인터프리터가 모듈을 찾는 경로 목록입니다. 기본적으로 Python 설치 디렉토리와 현재 작업 디렉토리가 포함되어 있습니다.
3. `sys.path.insert(0, "/Users/jinhwan/Repository/Labs/opensearch-with-bedrock-workshop-kr/utils")`는 `sys.path` 리스트의 맨 앞에 `/Users/jinhwan/Repository/Labs/opensearch-with-bedrock-workshop-kr/utils` 디렉토리를 추가합니다.

이렇게 함으로써 Python 인터프리터가 모듈을 찾을 때 `/Users/jinhwan/Repository/Labs/opensearch-with-bedrock-workshop-kr/utils` 디렉토리를 가장 먼저 검색하게 됩니다.

이 코드는 일반적으로 프로젝트 내에서 사용자 정의 모듈이나 유틸리티 함수를 import할 때 사용됩니다. 예를 들어, `utils` 디렉토리에 `my_utils.py` 파일이 있다면, 이 코드 실행 후 `import my_utils`를 통해 해당 모듈을 불러올 수 있습니다.

```python
# Add system path for utils
import sys

sys.path.insert(0, "/Users/jinhwan/Repository/Labs/opensearch-with-bedrock-workshop-kr/utils")
```
이 코드는 AWS 클라우드 서비스를 사용하여 OpenSearch 도메인 및 관련 자격 증명에 대한 정보를 가져오는 역할을 합니다. 주요 단계는 다음과 같습니다:

1. `boto3`와 `json` 라이브러리, 그리고 사용자 정의 함수 `get_cfn_outputs`를 임포트합니다.
2. AWS 리전 이름을 `us-east-1`로 설정합니다.
3. `boto3` 라이브러리를 사용하여 CloudFormation과 Secrets Manager 클라이언트를 생성합니다.
4. CloudFormation 스택 이름을 `opensearch-workshop`로 설정합니다.
5. `get_cfn_outputs` 함수를 호출하여 해당 스택의 출력 값들을 가져옵니다.
6. Secrets Manager에서 `OpenSearchSecret`이라는 이름의 비밀 값을 가져와 OpenSearch 자격 증명 정보를 JSON 형태로 파싱합니다.
7. CloudFormation 출력 값에서 OpenSearch 도메인 엔드포인트 주소를 가져옵니다.

이 코드를 통해 OpenSearch 도메인에 연결하는 데 필요한 자격 증명과 엔드포인트 주소를 가져올 수 있습니다. 이 정보를 사용하여 OpenSearch 클라이언트를 초기화하고 인덱싱, 검색 등의 작업을 수행할 수 있습니다.

```python
import boto3, json
from utils import get_cfn_outputs

region_name = "us-east-1"

cfn = boto3.client("cloudformation", region_name)
kms = boto3.client("secretsmanager", region_name)

stackname = "opensearch-workshop"
cfn_outputs = get_cfn_outputs(stackname, cfn)

aos_credentials = json.loads(
    kms.get_secret_value(SecretId=cfn_outputs["OpenSearchSecret"])["SecretString"]
)

aos_host = cfn_outputs["OpenSearchDomainEndpoint"]
```

드는 OpenSearch 클라이언트를 초기화하는 과정을 보여줍니다. 주요 단계는 다음과 같습니다:

1. `opensearchpy` 라이브러리에서 `OpenSearch`, `RequestsHttpConnection`, `AWSV4SignerAuth`를 임포트합니다.
2. 이전에 가져온 OpenSearch 자격 증명 정보에서 `username`과 `password`를 `auth` 변수에 저장합니다.
3. `OpenSearch` 클래스를 사용하여 `aos_client` 객체를 생성합니다. 이때 다음과 같은 파라미터를 설정합니다:
    - `hosts`: OpenSearch 도메인의 엔드포인트 주소와 포트 번호를 리스트 형태로 전달합니다.
    - `http_auth`: 인증에 사용할 `auth` 변수를 전달합니다.
    - `use_ssl`: HTTPS 연결을 사용할지 여부를 지정합니다 (True로 설정).
    - `verify_certs`: SSL 인증서 검증 여부를 지정합니다 (True로 설정).
    - `connection_class`: HTTP 연결에 사용할 클래스를 지정합니다 (`RequestsHttpConnection`으로 설정).

이렇게 초기화된 `aos_client` 객체를 사용하여 OpenSearch 도메인에 연결하고, 인덱싱, 검색, 문서 관리 등의 작업을 수행할 수 있습니다. 인증 정보와 엔드포인트 주소를 적절히 설정하여 OpenSearch 클라이언트를 안전하게 초기화하는 것이 중요합니다.

```python
from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth

auth = (aos_credentials["username"], aos_credentials["password"])

aos_client = OpenSearch(
    hosts=[{"host": aos_host, "port": 443}],
    http_auth=auth,
    use_ssl=True,
    verify_certs=True,
    connection_class=RequestsHttpConnection,
)
```

이 코드는 OpenSearch의 `_analyze` 엔드포인트를 사용하여 한국어 텍스트를 분석하는 예제입니다. 주요 단계는 다음과 같습니다:

1. `request_body`라는 딕셔너리를 생성하고, `analyzer`로 `nori`(한국어 분석기)를 지정하고, 분석할 `text`로 "OpenSearch 워크샵에 오신 고객 여러분 환영합니다."라는 문장을 설정합니다.
2. `aos_client.indices.analyze` 메서드를 호출하여 `_analyze` 엔드포인트로 요청을 보냅니다. 이때 `request_body`를 `body` 파라미터로 전달합니다.
3. 요청에 대한 응답을 `response` 변수에 저장합니다.
4. `json.dumps` 함수를 사용하여 `response`를 JSON 형식의 문자열로 변환하고, `indent=4`를 지정하여 들여쓰기를 적용하고, `ensure_ascii=False`를 지정하여 유니코드 문자를 그대로 출력합니다. 그리고 이를 `print` 함수로 출력합니다.

이 코드를 실행하면 OpenSearch의 `nori` 분석기가 "OpenSearch 워크샵에 오신 고객 여러분 환영합니다."라는 문장을 어떻게 토큰화하고 분석하는지 확인할 수 있습니다. 출력 결과에는 각 토큰의 유형, 위치, 원본 텍스트 등의 정보가 포함됩니다.

이렇게 `_analyze` 엔드포인트를 사용하면 OpenSearch의 분석기가 텍스트를 어떻게 처리하는지 미리 확인할 수 있습니다. 이를 통해 적절한 분석기 설정을 하고, 검색 품질을 높일 수 있습니다.

```python
request_body = {"analyzer": "nori", "text": "OpenSearch 워크샵에 오신 고객 여러분 환영합니다."}

# Send the request to the _analyze endpoint
response = aos_client.indices.analyze(body=request_body)

# Print the response
print(json.dumps(response, indent=4, ensure_ascii=False))
```

이 코드는 OpenSearch에 새로운 인덱스 `webtoon_lexical`을 생성하는 과정을 보여줍니다. 주요 단계는 다음과 같습니다:

1. `index_name`을 `"webtoon_lexical"`로 설정합니다.
2. 기존에 같은 이름의 인덱스가 있다면 `aos_client.indices.delete(index=index_name)`를 통해 삭제합니다.
3. `webtoon_lexical` 딕셔너리를 생성하여 인덱스 설정과 매핑을 정의합니다.
    - `settings`에서 복제본 수(0), 샤드 수(1), 최대 결과 창 크기(15000), 분석기(`nori` 분석기 사용)를 설정합니다.
    - `mappings`에서 각 필드의 데이터 타입과 옵션을 정의합니다. 예를 들어, `title`, `author`, `genre`, `description` 필드는 `text` 타입이며, 키워드 필드도 가지고 있습니다. `date` 필드는 날짜 타입이며, 특정 형식을 지정합니다.
4. 이렇게 정의된 `webtoon_lexical` 딕셔너리를 사용하여 OpenSearch에 새로운 인덱스를 생성할 수 있습니다.

이 코드는 웹툰 데이터를 저장하고 검색하기 위한 인덱스를 생성합니다. 각 필드의 데이터 타입과 옵션을 적절히 설정하여 효율적인 검색과 데이터 관리가 가능하도록 합니다. 특히 한국어 분석을 위해 `nori` 분석기를 사용하고 있습니다.

```python
index_name = "webtoon_lexical"

aos_client.indices.delete(index=index_name)

webtoon_lexical = {
    "settings": {
        "number_of_replicas": 0,
        "number_of_shards": 1,
        "max_result_window": 15000,
        "analysis": {"analyzer": {"analysis-nori": {"type": "nori", "stopwords": "_korean_"}}},
    },
    "mappings": {
        "properties": {
            "id": {"type": "integer"},
            "title": {
                "type": "text",
                "fields": {"keyword": {"type": "keyword", "ignore_above": 256}},
            },
            "author": {
                "type": "text",
                "fields": {"keyword": {"type": "keyword", "ignore_above": 256}},
            },
            "genre": {
                "type": "text",
                "fields": {"keyword": {"type": "keyword", "ignore_above": 256}},
            },
            "description": {
                "type": "text",
                "fields": {"keyword": {"type": "keyword", "ignore_above": 256}},
            },
            "date": {
                "type": "date",
                "format": "yyyy.MM.dd HH:mm",
            },  # '2020.10.07 23:00'
            "completed": {
                "type": "boolean",
            },
            "age": {
                "type": "keyword",
            },
            "free": {
                "type": "boolean",
            },
            "link": {
                "type": "keyword",
            },
        }
    },
}
```

이 코드는 Pandas DataFrame을 OpenSearch 엔진에 병렬로 벌크 인서트하는 과정을 보여줍니다. 주요 단계는 다음과 같습니다:

1. `tqdm`과 `opensearchpy` 라이브러리를 임포트합니다.
2. Pandas DataFrame `df`를 JSON 형식의 문자열로 변환하고, 이를 개별 JSON 문서로 분리합니다.
3. `_generate_data` 함수를 정의하여 각 JSON 문서를 OpenSearch 인덱스에 맞는 형식으로 변환합니다.
4. `helpers.parallel_bulk` 함수를 사용하여 JSON 문서를 OpenSearch에 병렬로 벌크 인서트합니다. 이 과정에서 `chunk_size`, `thread_count`, `queue_size` 등의 파라미터를 설정할 수 있습니다.
5. 인서트 성공/실패 여부에 따라 `succeeded`, `failed` 리스트에 각각 추가합니다.

이 코드를 통해 대용량 데이터를 효율적으로 OpenSearch에 인덱싱할 수 있습니다. 병렬 처리를 활용하여 성능을 높이고, 인서트 결과를 추적할 수 있습니다.

```python
from tqdm import tqdm
from opensearchpy import helpers

json_data = df.to_json(orient="records", lines=True)
docs = json_data.split("\n")[:-1]  # To remove the last empty line

def _generate_data():
    for doc in docs:
        yield {"_index": index_name, "_source": doc}

succeeded = []
failed = []
for success, item in helpers.parallel_bulk(
    aos_client, actions=_generate_data(), chunk_size=10, thread_count=2, queue_size=2
):
    if success:
        succeeded.append(item)
    else:
        failed.append(item)
```

이 코드는 OpenSearch 엔진에서 키워드 검색을 수행하고 결과를 DataFrame으로 반환하는 함수입니다. 주요 단계는 다음과 같습니다:

1. `keyword_search` 함수는 검색어 `query_text`를 인자로 받습니다.
2. OpenSearch의 `multi_match` 쿼리를 사용하여 `title`, `genre`, `description` 필드에서 `query_text`를 검색합니다. 최대 10개의 결과를 반환하도록 설정되어 있습니다.
3. `aos_client.search` 함수를 사용하여 OpenSearch에 쿼리를 전송하고 결과를 받습니다.
4. 검색 결과에서 각 문서의 `_score`(관련성 점수), `id`, `title`, `author`, `genre`, `description`, `date`, `completed`, `age`, `free`, `link` 필드를 추출하여 `query_result` 리스트에 저장합니다.
5. `query_result` 리스트를 Pandas DataFrame으로 변환하고, 열 이름을 지정합니다.
6. 최종 결과인 `query_result_df`를 출력합니다.

이 함수를 사용하면 OpenSearch 인덱스에서 특정 키워드를 검색할 수 있으며, 검색 결과를 DataFrame 형태로 받을 수 있습니다. 관련성 점수가 높은 상위 10개의 문서가 반환됩니다.

```python
def keyword_search(query_text):
    query = {
        "size": 10,
        "query": {
            "multi_match": {
                "query": query_text,
                "fields": ["title", "genre", "description"],
            }
        },
    }

    res = aos_client.search(index=index_name, body=query)

    query_result = []
    for hit in res["hits"]["hits"]:
        row = [
            hit["_score"],
            hit["_source"]["id"],
            hit["_source"]["title"],
            hit["_source"]["author"],
            hit["_source"]["genre"],
            hit["_source"]["description"],
            hit["_source"]["date"],
            hit["_source"]["completed"],
            hit["_source"]["age"],
            hit["_source"]["free"],
            hit["_source"]["link"],
        ]
        query_result.append(row)

    query_result_df = pd.DataFrame(
        data=query_result,
        columns=[
            "_score",
            "id",
            "title",
            "author",
            "genre",
            "description",
            "date",
            "completed",
            "age",
            "free",
            "link",
        ],
    )
    display(query_result_df)
```

# 키워드 검색 쿼리 수행

이 코드는 `keyword_search` 함수를 호출하면서 "강호 제일검이 어린 아이로 다시 태어난다"라는 검색어를 인자로 전달하고 있습니다.

`keyword_search` 함수는 다음과 같은 역할을 합니다:

1. OpenSearch의 `multi_match` 쿼리를 사용하여 `title`, `genre`, `description` 필드에서 해당 검색어를 검색합니다.
2. 최대 10개의 검색 결과를 반환하도록 설정되어 있습니다.
3. OpenSearch에 쿼리를 전송하고 결과를 받습니다.
4. 검색 결과에서 각 문서의 `_score`(관련성 점수), `id`, `title`, `author`, `genre`, `description`, `date`, `completed`, `age`, `free`, `link` 필드를 추출합니다.
5. 추출한 데이터를 Pandas DataFrame으로 변환하고, 열 이름을 지정합니다.
6. 최종 결과인 DataFrame을 출력합니다.

따라서 이 코드를 실행하면 "강호 제일검이 어린 아이로 다시 태어난다"라는 검색어와 관련된 상위 10개의 웹툰 정보가 DataFrame 형태로 출력될 것입니다. 각 행에는 해당 웹툰의 제목, 작가, 장르, 설명, 날짜, 완결 여부, 연령 등급, 무료 여부, 링크 등의 정보가 포함됩니다.

```bash
keyword_search("강호 제일검이 어린 아이로 다시 태어난다")
```

결과를 확인합니다.