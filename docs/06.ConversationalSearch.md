# Overview

대화형 검색은 사용자가 자연스럽게 질문하면 인공지능 시스템이 이해하고 관련 정보를 제공하는 방식을 말합니다. 단순히 키워드를 검색하는 것이 아니라, 실제 대화를 통해 정보를 얻습니다. 이는 사용자가 보다 자연스럽게 원하는 정보를 찾을 수 있게 해주며, 키워드를 입력하는 대신 대화를 통해 원하는 내용을 명확히 전달할 수 있습니다. 더불어, 지속적인 대화를 통해 추가적인 정보를 요청하거나 세부 사항을 파악하는 것도 가능합니다.

## Prerequisite

이번 단계를 진행하기 위해서는 [시맨틱 검색 단계](./03.SemanticSearch.md)를 필수적으로 완료하셔야 합니다.

## 사전 준비

인덱스 생성과 데이터 적재는 이미 [시맨틱 검색 단계](./03.SemanticSearch.md)에서 완료 했습니다. Amazon OpenSearch Service로의 연결은 [시맨틱 검색 단계](./03.SemanticSearch.md)와 동일하게 수행합니다. 

# 대화형 검색 구현

## LangChain의 Retriever 클래스 생성

OpenSearch 인덱스에서 문서를 검색하고 검색 결과를 반환하는 OpenSearchLexicalSearchRetriever 클래스를 정의합니다. 이 클래스는 lexical 검색(제목, 텍스트, 장르 등의 필드에서 텍스트 일치) 및 벡터 검색(사전 계산된 문서 임베딩 벡터 사용)을 결합하여 관련 문서를 검색합니다. 검색 결과는 정규화 및 결합 기술을 적용한 후 Document 객체 목록으로 반환됩니다.

```python
from langchain.callbacks.manager import CallbackManagerForRetrieverRun
from langchain.schema import BaseRetriever
from typing import Any, List
from langchain.schema import Document

class OpenSearchLexicalSearchRetriever(BaseRetriever):
    os_client: Any
    index_name: str
    k = 10
    minimum_should_match = 0
    filter = []

    def _reset_search_params(
        self,
    ):

        self.k = 10
        self.minimum_should_match = 0
        self.filter = []

    def _get_relevant_documents(
        self, query: str, *, run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        body = {
            "size": self.k,
            "_source": {"exclude": ["vector_field"]},
            "query": {
                "hybrid": {
                    "queries": [
                        {
                            "multi_match": {
                                "query": query_text,
                                "fields": ["title", "text", "genre"],
                            }
                        },
                        {
                            "neural": {
                                "vector_field": {
                                    "query_text": query_text,
                                    "model_id": "jK-l048BhWoFUAg8WOdO",
                                    "k": 30,
                                }
                            }
                        },
                    ]
                }
            },
            "search_pipeline": {
                "description": "Post processor for hybrid search",
                "phase_results_processors": [
                    {
                        "normalization-processor": {
                            "normalization": {"technique": "min_max"},
                            "combination": {
                                "technique": "arithmetic_mean",
                                "parameters": {"weights": [0.3, 0.7]},
                            },
                        }
                    }
                ],
            },
        }
        res = self.os_client.search(index=index_name, body=body)

        query_result = []

        for hit in res["hits"]["hits"]:
            metadata = {"score": hit["_score"], "id": hit["_id"]}

            content = {
                "title": hit["_source"]["title"],
                "genre": hit["_source"]["genre"],
                "rating": hit["_source"]["rating"],
                "text": hit["_source"]["text"],
                "score": hit["_score"],
            }

            doc = Document(page_content=json.dumps(content, ensure_ascii=False), metadata=metadata)
            query_result.append(doc)

        return query_result
```

## Retriever 클래스로 문서 검색 테스트

앞서 정의된 **`OpenSearchLexicalSearchRetriever`** 클래스를 사용하여 OpenSearch 인덱스에서 하이브리드 검색을 수행하고, 검색 결과를 기반으로 질문에 대한 답변을 생성합니다.

```python
hybrid_retriever = OpenSearchLexicalSearchRetriever(os_client=aos_client, index_name=index_name)

search_hybrid_result = hybrid_retriever.get_relevant_documents(query_text)

answer = chain.run(input_documents=search_hybrid_result, question=query_text)

print("##############################")
print("query: \n", query_text)
print("answer: \n", answer)
```

## 영화 추천을 위한 프롬프트 생성

영화 추천 시스템을 위한 프롬프트 템플릿을 정의합니다. 

```python
prompt_template = """

Human: Here is the list of recommended movies, inside <movies></movies> XML tags.

<movies>
{context}
</movies>

Only using the contex as above, answer the following question with the rules as below:
    - Don't insert XML tag such as <context> and </context> when answering.
    - Write as much as you can
    - Be courteous and polite
    - Only answer the question if you can find the answer in the context with certainty.

You are a best movie reviewer in Korea. Please recommend a movies from the list above.

Question:
{question}

If the answer is not in the context, just say "추천해드릴만한 영화가 없습니다."

Assistant:"""

PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
```

프롬프트 템플릿은 다음과 같은 구조를 가지고 있습니다.

1. 영화 목록이 `<movies>` 태그 안에 포함되어 있습니다.
2. 답변 시 다음 규칙을 따라야 합니다:
    - XML 태그를 삽입하지 않습니다.
    - 가능한 한 많은 내용을 작성합니다.
    - 공손하고 예의 바른 태도를 유지합니다.
    - 컨텍스트에서 확실한 답변을 찾을 수 있는 경우에만 답변합니다.
3. 질문에 대한 답변을 작성할 때, 한국에서 가장 유명한 영화 평론가의 역할을 합니다.
4. 컨텍스트에 답변이 없는 경우 "추천해드릴만한 영화가 없습니다."라고 답변합니다.

이 프롬프트 템플릿은 `PromptTemplate` 클래스를 사용하여 정의되었으며, `input_variables`로 `context`와 `question`을 받습니다. 이 템플릿은 영화 추천 시스템에서 사용자의 질문에 대한 답변을 생성하는 데 사용될 수 있습니다.

## Condense Template 생성

주어진 대화 내용과 후속 질문을 바탕으로 하나의 독립적인 요약 질문을 생성하기 위한 프롬프트 템플릿을 정의합니다.

```python
condense_template = """
Generate one standalone question based on the instructions.

<instrunctions>
- You will be given the following conversation between <chat-history> and </chat-history>
- You will be given the following follow up question between <follow-up-question> and </follow-up-question>
- Standalone question should have summary of the previous questions and answers.
</instructions>

<chat-history>
{chat_history}
</chat-history>

<follow-up-question>
{question}
</follow-up-question>

standalone question:
"""

CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(condense_template)
```

이 템플릿을 사용하면 대화 내용과 후속 질문을 입력값으로 제공하여 하나의 요약 질문을 생성할 수 있습니다. 이는 대화형 AI 시스템이나 질문 답변 애플리케이션 등에서 유용하게 사용될 수 있습니다.

## ConversationalRetrievalChain을 사용한 대화형 검색 시스템 구축

LangChain 라이브러리를 사용하여 대화형 검색 시스템을 구축합니다. ConversationalRetrievalChain은 대화 기반 질의응답 시스템을 만드는 데 사용되는 LangChain의 핵심 컴포넌트입니다.

```python
from langchain.chains import ConversationalRetrievalChain

memory.clear()

conversation_with_retrieval = ConversationalRetrievalChain.from_llm(
    llm,
    retriever=hybrid_retriever,
    memory=memory,
    combine_docs_chain_kwargs={"prompt": PROMPT},
    condense_question_prompt=CONDENSE_QUESTION_PROMPT,
    verbose=True,
)

```

이 코드를 실행하면 대화형 검색 시스템이 구축되어 사용자와 상호작용할 수 있게 됩니다. 사용자는 질문을 입력하면 시스템이 관련 문서를 검색하고, 언어 모델을 사용하여 문서를 기반으로 답변을 생성합니다. 대화 기록은 메모리에 저장되어 후속 질문에 대한 컨텍스트를 제공합니다.

# 대화형으로 영화 추천 받아보기

## 첫번째 질문하기

이제 대화형으로 검색을 시작해봅시다.

```python
query_text = "우주에서 벌어지는 전쟁이야기"

chat_response = conversation_with_retrieval.invoke({"question": query_text})

print(textwrap.fill(chat_response["answer"], 80))
```

다음과 같은 답변을 받을 수 있습니다. 

> (Independence Day: Resurgence) - 장르: 액션, 모험, SF - 평점: 7.25 - 줄거리: 2년 전 최악의 우주
전쟁을 치른 지구가 다시 한번 외계의 침공에 맞서 인류 최후의 전쟁을 펼치는 이야기입니다.  2. 스페셜 솔져 (Special Soldier)
> 
> - 장르: 액션, 전쟁 - 평점: 6.8 - 줄거리: 세계 곳곳에서 전쟁이 동시다발적으로 터지면서 특수부대가 출동하여 현재와 미래를 건 전쟁에
> 맞서는 내용입니다. 두 영화 모두 우주와 지구를 배경으로 전쟁 이야기를 그리고 있어 추천해드립니다.

## 두번째 질문하기

대화형 검색에서는 이전 검색의 질문과 답변을 기억하고 있습니다. 따라서 질문 안의 “그 영화”가 추천해준 영화인 것을 알고 있고 여기에 맞춰 자연스럽게 사람처럼 답변을 해줄 수 있습니다.

```python
chat_response = conversation_with_retrieval.invoke({"question": "그 영화 평점은?"})

print(textwrap.fill(chat_response["answer"], 80))
```

답변은 다음과 같습니다.

> '인디펜던스 데이: 리써전스'의 평점은 7.25, '스페셜 솔져'의 평점은 6.8입니다. 두 영화 모두 우주에서 벌어지는 전쟁 이야기를 다루고 있습니다.
> 

## 세번째 질문하기

여기서도 비슷한 장르가 “이전에 추천해줬던 영화와 비슷한 장르”를 의미하는 것을 알 수 있습니다.

```python
chat_response = conversation_with_retrieval.invoke({"question": "비슷한 장르의 다른 영화는?"})

print(textwrap.fill(chat_response["answer"], 80))
```

답변은 다음과 같습니다.

> 제가 보기에는 '다이버전트 시리즈: 얼리전트'(평점 7.28)가 우주에서 벌어지는 전쟁 이야기 영화로 '인디펜던스 데이: 리써전스'와 '스페셜
솔져'와 비슷한 장르의 영화라고 생각됩니다. 영화 설명에 "장벽 너머의 새로운 미래에 당도한 다이버전트 군단. 진실을 숨긴 채 인류를
실험대상으로 삼으려는 감시자들에 맞선 최후의 생존전쟁이 시작된다!"라고 나와 있어 우주에서 벌어지는 전쟁 이야기임을 알 수 있습니다.
> 

### 성공적으로 대화형 검색을 구현하셨습니다! 축하드립니다!