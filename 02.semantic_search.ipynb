{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 시맨틱 검색 - Semantic Search\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 시맨틱 검색 (Semantic Search)\n",
                "\n",
                "오픈서치의 시맨틱 검색은 검색 쿼리의 의미를 이해하고, 그에 따라 가장 관련성 높은 결과를 사용자에게 제공하는 기능입니다. 이는 전통적인 키워드 기반 검색과 달리, 검색 쿼리의 맥락과 의미를 분석하여 보다 정확하고 관련성 높은 검색 결과를 제공합니다. 예를 들어 \"아마존\"이라는 단어가 상품명인지, 회사명인지, 아니면 지역명인지 등 쿼리의 의미를 파악하여 그에 맞는 검색 결과를 제공합니다.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 신경망 검색(Neural Search)\n",
                "\n",
                "수년 동안 고객들은 OpenSearch k-NN을 기반으로 시맨틱 검색 애플리케이션을 구축하기 위해서는 텍스트 임베딩 모델을 검색 및 수집 파이프라인에 통합하기 위해 추가적인 미들웨어를 구축해야 하는 부담이 있었습니다. 이제 Amazon SageMaker와 Amazon Bedrock와의 통합을 통해 신경망 검색을 강화하며 클러스터에서 실행되는 시맨틱 검색 파이프라인을 지원할 수 있습니다.\n",
                "\n",
                "신경망 검색은 텍스트를 벡터로 변환하고 인덱싱 시간과 검색 시간 모두에서 벡터 검색을 용이하게 합니다. 인덱싱 중에 신경망 검색은 문서 텍스트를 벡터 임베딩으로 변환하고 텍스트와 그 벡터 임베딩을 모두 벡터 인덱스에 인덱싱합니다. 신경망 쿼리를 사용하는 경우 신경망 검색은 쿼리 텍스트를 벡터 임베딩으로 변환하고, 벡터 검색을 사용하여 쿼리와 문서 임베딩을 비교한 다음 가장 가까운 결과를 반환합니다.\n",
                "\n",
                "문서를 인덱스에 인제스트하기 전에 문서는 기계 학습(ML) 모델을 통과하게 되며, 이 모델은 문서 필드에 대한 벡터 임베딩을 생성합니다. 검색 요청을 보내면 쿼리 텍스트나 이미지도 ML 모델을 통과하여 해당 벡터 임베딩을 생성합니다. 그런 다음 신경망 검색이 임베딩에 대한 벡터 검색을 수행하고 일치하는 문서를 반환합니다.\n",
                "\n",
                "신경망 검색을 사용하면 OpenSearch API를 통해 인간의 언어로 검색 쿼리를 실행하고, Amazon SageMaker에서 호스팅되거나 Amazon Bedrock에서 관리하는 텍스트 임베딩을 통해 의미론적 이해와 유사성을 고려한 텍스트 임베딩을 사용하여 더 정확한 결과를 제공할 수 있습니다.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 사전준비\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "필요한 패키지를 설치합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q boto3\n",
                "!pip install -q requests\n",
                "!pip install -q requests-aws4auth\n",
                "!pip install -q opensearch-py\n",
                "!pip install -q tqdm\n",
                "!pip install -q boto3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "키워드 검색 단계에서와 마찬가지로 데이터를 준비합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import requests\n",
                "\n",
                "df = pd.read_csv(\"./data/movies.csv\", low_memory=False)\n",
                "df.head(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "데이터의 스키마를 확인합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이 워크샵에서 사용할 임베딩 모델인 Cohere Embed Multilingual의 Max Sequence 길이는 512입니다. 따라서 여기에 맞게 임베딩할 plot 컬럼의 최대 길이를 512로 truncate합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_length = 509\n",
                "\n",
                "\n",
                "def truncate_plot(plot):\n",
                "    if len(plot) > max_length:\n",
                "        return plot[:max_length] + \"...\"\n",
                "    else:\n",
                "        return plot\n",
                "\n",
                "\n",
                "# Apply the function to the 'plot' column\n",
                "df[\"plot\"] = df[\"plot\"].apply(truncate_plot)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "줄거리의 길이가 512가 넘는 레코드가 있는지 확인합니다\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find all items in df  with plot value longer than 512 characters\n",
                "def find_long_plot_items(df):\n",
                "    long_plot_items = df[df[\"plot\"].str.len() > 512]\n",
                "    return long_plot_items\n",
                "\n",
                "\n",
                "find_long_plot_items(df).count()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### OpenSearch 도메인에 연결\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_cfn_outputs(stackname, cfn):\n",
                "    outputs = {}\n",
                "    for output in cfn.describe_stacks(StackName=stackname)[\"Stacks\"][0][\"Outputs\"]:\n",
                "        outputs[output[\"OutputKey\"]] = output[\"OutputValue\"]\n",
                "    return outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'search-opensearch-workshop-rgx5p7rgxyxhec6mi3kusldapu.us-west-2.es.amazonaws.com'"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import boto3, json\n",
                "\n",
                "\n",
                "region_name = \"us-west-2\"\n",
                "\n",
                "cfn = boto3.client(\"cloudformation\", region_name)\n",
                "kms = boto3.client(\"secretsmanager\", region_name)\n",
                "\n",
                "stackname = \"opensearch-workshop\"\n",
                "cfn_outputs = get_cfn_outputs(stackname, cfn)\n",
                "\n",
                "aos_credentials = json.loads(\n",
                "    kms.get_secret_value(SecretId=cfn_outputs[\"OpenSearchSecret\"])[\"SecretString\"]\n",
                ")\n",
                "\n",
                "aos_host = cfn_outputs[\"OpenSearchDomainEndpoint\"]\n",
                "aos_host"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
                "\n",
                "auth = (aos_credentials[\"username\"], aos_credentials[\"password\"])\n",
                "\n",
                "aos_client = OpenSearch(\n",
                "    hosts=[{\"host\": aos_host, \"port\": 443}],\n",
                "    http_auth=auth,\n",
                "    use_ssl=True,\n",
                "    verify_certs=True,\n",
                "    connection_class=RequestsHttpConnection,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 데이터 임베딩을 위한 Ingest Pipeline 생성\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "모델 배포 과정을 참고하여 배포된 모델의 ID를 확인하고 아래와 같이 변수에 초기화합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import requests\n",
                "\n",
                "search_model = {\"query\": {\"match\": {\"name\": \"OpenSearch-Cohere\"}}, \"size\": 10}\n",
                "\n",
                "response = requests.get(\n",
                "    \"https://\" + aos_host + \"/_plugins/_ml/models/_search\", auth=auth, json=search_model\n",
                ")\n",
                "model_info = json.loads(response.text)\n",
                "model_id = model_info[\"hits\"][\"hits\"][0][\"_id\"]\n",
                "model_id"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 인제스트 파이프라인 생성\n",
                "\n",
                "영화의 줄거리 정보를 가진 특정 필드(\"plot\")에 대한 벡터 임베딩을 생성하는 파이프라인을 설정합니다. 이러한 임베딩은 검색 인덱스 필드(\"vector_field\")에 저장되며, 효율적인 유사성 검색 및 검색 작업에 사용될 수 있습니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pipeline = {\n",
                "    \"description\": \"An neural search pipeline for movie index - OpenSearch-cohere-060124084807\",\n",
                "    \"processors\": [\n",
                "        {\n",
                "            \"text_embedding\": {\n",
                "                \"model_id\": model_id,\n",
                "                \"field_map\": {\n",
                "                    \"plot\": \"vector_field\",\n",
                "                },\n",
                "            }\n",
                "        }\n",
                "    ],\n",
                "}\n",
                "\n",
                "pipeline_id = \"movie_plot_embedding_pipeline\"\n",
                "aos_client.ingest.put_pipeline(id=pipeline_id, body=pipeline)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 인덱스 생성\n",
                "\n",
                "movie_semantic 인덱스를 생성합니다. 아래 세팅 및 맵핑 정보 중 중요한 것은 다음과 같습니다.\n",
                "\n",
                "-   index.knn: KNN 검색을 위해 True로 설정합니다.\n",
                "-   default_pipeline: 위 단계에서 생성한 pipeline_id를 제공합니다.\n",
                "-   index.knn.space_type: 임베딩 벡터끼리의 유사도를 파악할 때 사용할 알고리즘을 cosinesimil로 지정합니다\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "index_name = \"movie_semantic\"\n",
                "\n",
                "# aos_client.indices.delete(index=index_name)\n",
                "\n",
                "movie_semantic = {\n",
                "    \"settings\": {\n",
                "        \"max_result_window\": 15000,\n",
                "        \"analysis\": {\"analyzer\": {\"analysis-nori\": {\"type\": \"nori\", \"stopwords\": \"_korean_\"}}},\n",
                "        \"index.knn\": True,\n",
                "        \"default_pipeline\": pipeline_id,\n",
                "        \"index.knn.space_type\": \"cosinesimil\",\n",
                "    },\n",
                "    \"mappings\": {\n",
                "        \"properties\": {\n",
                "            \"date\": {\n",
                "                \"type\": \"float\",\n",
                "            },\n",
                "            \"genre\": {\n",
                "                \"type\": \"text\",\n",
                "            },\n",
                "            \"main_act\": {\n",
                "                \"type\": \"text\",\n",
                "                \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
                "            },\n",
                "            \"plot\": {\n",
                "                \"type\": \"text\",\n",
                "            },\n",
                "            \"rating\": {\"type\": \"float\"},\n",
                "            \"supp_act\": {\n",
                "                \"type\": \"text\",\n",
                "                \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
                "            },\n",
                "            \"title\": {\n",
                "                \"type\": \"text\",\n",
                "                \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
                "            },\n",
                "            \"vote_count\": {\"type\": \"long\"},\n",
                "            \"year\": {\"type\": \"long\"},\n",
                "            \"vector_field\": {\n",
                "                \"type\": \"knn_vector\",\n",
                "                \"dimension\": 1024,\n",
                "                \"method\": {\"name\": \"hnsw\", \"space_type\": \"l2\", \"engine\": \"faiss\"},\n",
                "                \"store\": True,\n",
                "            },\n",
                "        }\n",
                "    },\n",
                "}\n",
                "\n",
                "aos_client.indices.create(index=index_name, body=movie_semantic)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 데이터 인제스트\n",
                "\n",
                "키워드 검색과 동일하게 데이터를 인제스트합니다. 위 단계에서 인덱스를 생성할 때 INGEST PIPELINE을 설정했기 때문에 직접 임베딩 모델을 호출하여 데이터를 벡터로 변환하지 않아도 됩니다. 단, 데이터가 인제스트될 때 임베딩 모델을 호출해야 하는 단계가 있기 때문에 parallel_bulk의 병렬도가 높으면 에러가 발생할 있습니다. 여기서는 `thread_count`와 `queue_size`를 각각 1로 낮춰줍니다. 이 단계가 완료되는데는 약 4~5분 정도 소요됩니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm\n",
                "from opensearchpy import helpers\n",
                "\n",
                "json_data = df.to_json(orient=\"records\", lines=True)\n",
                "docs = json_data.split(\"\\n\")[:-1]  # To remove the last empty line\n",
                "\n",
                "\n",
                "def _generate_data():\n",
                "    for doc in docs:\n",
                "        yield {\"_index\": index_name, \"_source\": doc}\n",
                "\n",
                "\n",
                "succeeded = []\n",
                "failed = []\n",
                "for success, item in helpers.parallel_bulk(\n",
                "    aos_client, actions=_generate_data(), chunk_size=20, thread_count=1, queue_size=1\n",
                "):\n",
                "    if success:\n",
                "        succeeded.append(item)\n",
                "    else:\n",
                "        failed.append(item)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "데이터 인제스트가 잘 마무리되었는지 확인합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Refresh the index to make the changes visible\n",
                "aos_client.indices.refresh(index=index_name)\n",
                "\n",
                "count = aos_client.count(index=index_name)\n",
                "print(count)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 키워드 검색과 시맨틱 검색 결과 비교\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 키워드 검색을 위한 함수 생성\n",
                "\n",
                "키워드 단계에서 정의한 키워드 검색 함수와 동일한 함수를 생성합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def keyword_search(query_text):\n",
                "    query = {\n",
                "        \"size\": 10,\n",
                "        \"query\": {\n",
                "            \"multi_match\": {\n",
                "                \"query\": query_text,\n",
                "                \"fields\": [\"plot\"],\n",
                "            }\n",
                "        },\n",
                "    }\n",
                "\n",
                "    res = aos_client.search(index=index_name, body=query)\n",
                "\n",
                "    query_result = []\n",
                "    for hit in res[\"hits\"][\"hits\"]:\n",
                "        row = [\n",
                "            hit[\"_score\"],\n",
                "            hit[\"_source\"][\"title\"],\n",
                "            hit[\"_source\"][\"plot\"],\n",
                "            hit[\"_source\"][\"genre\"],\n",
                "            hit[\"_source\"][\"rating\"],\n",
                "        ]\n",
                "        query_result.append(row)\n",
                "\n",
                "    query_result_df = pd.DataFrame(\n",
                "        data=query_result, columns=[\"_score\", \"title\", \"plot\", \"genre\", \"rating\"]\n",
                "    )\n",
                "    display(query_result_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 시맨팀 검색을 위한 함수 생성\n",
                "\n",
                "뉴럴 검색을 위한 함수를 생성합니다. 주목해야할 부분은 다음과 같습니다.\n",
                "\n",
                "1. **`\"_source\": {\"excludes\": [\"vector_field\"]}`**: 검색 결과에서 **`vector_field`** 필드를 제외한 모든 필드를 반환합니다. 이는 벡터 데이터가 크기 때문에 전송 비용을 줄이기 위함입니다.\n",
                "2. **`\"query\": { ... }`**: 실제 검색 쿼리를 정의합니다.\n",
                "3. **`\"neural\": { ... }`**: 벡터 검색을 수행하기 위한 쿼리 유형입니다.\n",
                "4. **`\"vector_field\": \"vector_field_name\"`**: 벡터 데이터가 저장된 필드 이름입니다.\n",
                "5. **`\"query_text\": query_text`**: 검색할 텍스트 쿼리입니다.\n",
                "6. **`\"model_id\": model_id`**: 벡터 임베딩을 생성하는 데 사용된 모델의 ID입니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def semantic_search(query_text):\n",
                "    query = {\n",
                "        \"size\": 10,\n",
                "        \"_source\": {\"excludes\": [\"vector_field\"]},\n",
                "        \"query\": {\n",
                "            \"neural\": {\"vector_field\": {\"query_text\": query_text, \"model_id\": model_id, \"k\": 10}},\n",
                "        },\n",
                "    }\n",
                "\n",
                "    res = aos_client.search(index=index_name, body=query)\n",
                "\n",
                "    query_result = []\n",
                "    for hit in res[\"hits\"][\"hits\"]:\n",
                "        row = [\n",
                "            hit[\"_score\"],\n",
                "            hit[\"_source\"][\"title\"],\n",
                "            hit[\"_source\"][\"plot\"],\n",
                "            hit[\"_source\"][\"genre\"],\n",
                "            hit[\"_source\"][\"rating\"],\n",
                "        ]\n",
                "        query_result.append(row)\n",
                "\n",
                "    query_result_df = pd.DataFrame(\n",
                "        data=query_result, columns=[\"_score\", \"title\", \"plot\", \"genre\", \"rating\"]\n",
                "    )\n",
                "    display(query_result_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 결과 비교\n",
                "\n",
                "자연어 기반의 쿼리를 작성하고 키워드 검색과 시맨틱 검색의 결과를 비교해봅니다\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query_text = \"지구의 영웅들이 힘을 합쳐 우주의 악당을 물리친다\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "keyword_search(query_text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "semantic_search(query_text)\n",
                "# print(index_name)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "opensearch",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
