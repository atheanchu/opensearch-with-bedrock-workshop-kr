{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 키워드 검색 - Lexical Search\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 사전 준비\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 패키지 및 데이터 준비\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "필요한 패키지를 설치합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q boto3\n",
                "!pip install -q requests\n",
                "!pip install -q requests-aws4auth\n",
                "!pip install -q opensearch-py\n",
                "!pip install -q tqdm\n",
                "!pip install -q boto3\n",
                "!pip install pandas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "워크샵에서 사용할 데이터 파일을 읽어 판다스 데이터프레임으로 저장합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import requests\n",
                "\n",
                "df = pd.read_csv(\"./data/movies.csv\", low_memory=False)\n",
                "df.head(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "데이터의 스키마와 레코드 수를 확인합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### OpenSearch 도메인에 연결하기\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "먼저 utils 디렉토리에 있는 공용모듈을 사용하기 위한 준비를 합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_cfn_outputs(stackname, cfn):\n",
                "    outputs = {}\n",
                "    for output in cfn.describe_stacks(StackName=stackname)[\"Stacks\"][0][\"Outputs\"]:\n",
                "        outputs[output[\"OutputKey\"]] = output[\"OutputValue\"]\n",
                "    return outputs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이 코드를 통해 OpenSearch 도메인에 연결하는 데 필요한 자격 증명과 엔드포인트 주소를 가져올 수 있습니다. 이 정보를 사용하여 OpenSearch 클라이언트를 초기화하고 인덱싱, 검색 등의 작업을 수행할 수 있습니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import boto3, json\n",
                "\n",
                "\n",
                "region_name = \"us-west-2\"\n",
                "\n",
                "cfn = boto3.client(\"cloudformation\", region_name)\n",
                "kms = boto3.client(\"secretsmanager\", region_name)\n",
                "\n",
                "stackname = \"opensearch-workshop\"\n",
                "cfn_outputs = get_cfn_outputs(stackname, cfn)\n",
                "\n",
                "aos_credentials = json.loads(\n",
                "    kms.get_secret_value(SecretId=cfn_outputs[\"OpenSearchSecret\"])[\"SecretString\"]\n",
                ")\n",
                "\n",
                "aos_host = cfn_outputs[\"OpenSearchDomainEndpoint\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "위의 코드로부터 가져온 호스트 URL과 인증정보를 통해 OpenSearch 도메인에 연결합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
                "\n",
                "auth = (aos_credentials[\"username\"], aos_credentials[\"password\"])\n",
                "\n",
                "aos_client = OpenSearch(\n",
                "    hosts=[{\"host\": aos_host, \"port\": 443}],\n",
                "    http_auth=auth,\n",
                "    use_ssl=True,\n",
                "    verify_certs=True,\n",
                "    connection_class=RequestsHttpConnection,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "연결이 잘 되었는지 확인하기 위해 간단한 요청을 보내보겠습니다. analyze 엔드포인트를 사용하여 nori 분석기로 간단한 한국어를 분석해 봅니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "request_body = {\"analyzer\": \"nori\", \"text\": \"OpenSearch 워크샵에 오신 고객 여러분 환영합니다.\"}\n",
                "\n",
                "# Send the request to the _analyze endpoint\n",
                "response = aos_client.indices.analyze(body=request_body)\n",
                "\n",
                "# Print the response\n",
                "print(json.dumps(response, indent=4, ensure_ascii=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 인덱스 생성\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이제 인덱스를 생성합니다. 인덱스의 이름은 movies_lexical 로 하고 맵핑 정보는 다음과 같이 지정합니다.|\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "index_name = \"movie_lexical\"\n",
                "\n",
                "movie_lexical = {\n",
                "    \"settings\": {\n",
                "        \"number_of_replicas\": 0,\n",
                "        \"number_of_shards\": 1,\n",
                "        \"max_result_window\": 15000,\n",
                "        \"analysis\": {\"analyzer\": {\"analysis-nori\": {\"type\": \"nori\", \"stopwords\": \"_korean_\"}}},\n",
                "    },\n",
                "    \"mappings\": {\n",
                "        \"properties\": {\n",
                "            \"date\": {\n",
                "                \"type\": \"float\",\n",
                "            },\n",
                "            \"genre\": {\n",
                "                \"type\": \"text\",\n",
                "            },\n",
                "            \"main_act\": {\n",
                "                \"type\": \"text\",\n",
                "                \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
                "            },\n",
                "            \"plot\": {\n",
                "                \"type\": \"text\",\n",
                "            },\n",
                "            \"rating\": {\"type\": \"float\"},\n",
                "            \"supp_act\": {\n",
                "                \"type\": \"text\",\n",
                "                \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
                "            },\n",
                "            \"title\": {\n",
                "                \"type\": \"text\",\n",
                "                \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
                "            },\n",
                "            \"vote_count\": {\"type\": \"long\"},\n",
                "            \"year\": {\"type\": \"long\"},\n",
                "        }\n",
                "    },\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "위의 맵핑 정보로 인덱스를 생성합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "aos_client.indices.create(index=index_name, body=movie_lexical)\n",
                "aos_client.indices.get(index=index_name)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 데이터 인제스트\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "생성된 인덱스에 데이터를 인제스트합니다. 여기서는 opensearchpy 패키지에서 제공하는 parallel_bulk를 사용하여 빠르게 데이터를 인제스트합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from opensearchpy import helpers\n",
                "\n",
                "# Pandas DataFrame을 JSON 형식의 문자열로 변환\n",
                "json_data = df.to_json(orient=\"records\", lines=True)\n",
                "# JSON 문자열을 개별 JSON 객체로 분할하고, 마지막 빈 줄을 제거\n",
                "docs = json_data.split(\"\\n\")[:-1]  # To remove the last empty line\n",
                "\n",
                "\n",
                "# JSON 객체를 OpenSearch에 업로드할 수 있는 형식으로 변환\n",
                "def _generate_data():\n",
                "    for doc in docs:\n",
                "        yield {\"_index\": index_name, \"_source\": doc}\n",
                "\n",
                "\n",
                "succeeded = []\n",
                "failed = []\n",
                "# 병렬로 벌크 업로드를 수행\n",
                "for success, item in helpers.parallel_bulk(\n",
                "    aos_client, actions=_generate_data(), chunk_size=20, thread_count=4, queue_size=4\n",
                "):\n",
                "    if success:\n",
                "        succeeded.append(item)\n",
                "    else:\n",
                "        failed.append(item)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "데이터가 바로 반영되도록 인덱스를 Refresh하고 인제스트가 잘 되었는지 확인하기 위해 도큐먼트의 총 합을 count로 확인합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "aos_client.indices.refresh(index=index_name)\n",
                "\n",
                "count = aos_client.count(index=index_name)\n",
                "print(count)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이제 키워드 검색을 수행할 모든 준비가 끝났습니다.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 키워드 검색 결과 확인하기\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "키워드 검색을 위한 헬퍼 함수를 생성합니다. 여기서는 상위 10개의 결과만을 확인합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def keyword_search(query_text):\n",
                "    query = {\n",
                "        \"size\": 10,\n",
                "        \"query\": {\n",
                "            \"multi_match\": {\n",
                "                \"query\": query_text,\n",
                "                \"fields\": [\"plot\"],\n",
                "            }\n",
                "        },\n",
                "    }\n",
                "\n",
                "    res = aos_client.search(index=index_name, body=query)\n",
                "\n",
                "    query_result = []\n",
                "    for hit in res[\"hits\"][\"hits\"]:\n",
                "        row = [\n",
                "            hit[\"_score\"],\n",
                "            hit[\"_source\"][\"title\"],\n",
                "            hit[\"_source\"][\"plot\"],\n",
                "            hit[\"_source\"][\"genre\"],\n",
                "            hit[\"_source\"][\"rating\"],\n",
                "            hit[\"_source\"][\"main_act\"],\n",
                "        ]\n",
                "        query_result.append(row)\n",
                "\n",
                "    query_result_df = pd.DataFrame(\n",
                "        data=query_result,\n",
                "        columns=[\"_score\", \"title\", \"plot\", \"genre\", \"rating\", \"main_act\"],\n",
                "    )\n",
                "    display(query_result_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "자연어로 검색결과를 확인해봅니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "keyword_search(\"지구의 영웅들이 힘을 합쳐 우주의 악당을 물리친다\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
