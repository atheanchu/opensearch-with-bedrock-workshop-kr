{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 하이브리드 - Hybrid Search\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hyrbid 검색이란?\n",
                "\n",
                "하이브리드 검색은 키워드 검색과 Neural Search 검색을 결합하여 검색 관련성을 향상시킵니다. 하이브리드 검색을 구현하려면 검색 시간에 실행되는 [검색 파이프라인](https://opensearch.org/docs/latest/search-plugins/search-pipelines/index/)을 설정해야 합니다. 구성할 검색 파이프라인은 중간 단계에서 검색 결과를 가로채고 [`normalization_processor`](https://opensearch.org/docs/latest/search-plugins/search-pipelines/normalization-processor/)를 적용합니다. `normalization_processor`는 여러 쿼리 절에서의 문서 점수를 정규화하고 결합하여, 선택한 정규화 및 결합 기법에 따라 문서를 재점수화합니다.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 사전 준비\n",
                "\n",
                "이번 단계를 진행하기 위해서는 [시맨틱 검색 단계](./02.semantic_search.ipynb)를 필수적으로 완료하셔야 합니다. Amazon OpenSearch Service로의 연결은 [시맨틱 검색 단계](./02.semantic_search.ipynb)와 동일하게 수행합니다. 단 여기서는 코드를 간결하게 하기 위해 utils.py에 정의한 keyword_search와 semantic_search 함수를 재사용합니다.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "필요한 패키지를 설치합니다\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q boto3\n",
                "!pip install -q requests\n",
                "!pip install -q requests-aws4auth\n",
                "!pip install -q opensearch-py\n",
                "!pip install -q tqdm\n",
                "!pip install -q boto3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### OpenSearch 도메인에 연결\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "CloudFormation 스택에서 필요한 정보를 가져오기 위한 함수를 선언합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add system path for utils\n",
                "import sys\n",
                "\n",
                "sys.path.insert(0, \"/Users/jinhwan/Repository/Labs/opensearch-with-bedrock-workshop-kr/utils\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "OpenSearch 도메인에 접속하기 위한 호스트 정보와 인증정보를 가져옵니다\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import boto3, json\n",
                "import pandas as pd\n",
                "from utils import get_cfn_outputs, keyword_search, semantic_search\n",
                "\n",
                "region_name = \"us-west-2\"\n",
                "\n",
                "cfn = boto3.client(\"cloudformation\", region_name)\n",
                "kms = boto3.client(\"secretsmanager\", region_name)\n",
                "\n",
                "stackname = \"opensearch-workshop\"\n",
                "cfn_outputs = get_cfn_outputs(stackname, cfn)\n",
                "\n",
                "aos_credentials = json.loads(\n",
                "    kms.get_secret_value(SecretId=cfn_outputs[\"OpenSearchSecret\"])[\"SecretString\"]\n",
                ")\n",
                "\n",
                "aos_host = cfn_outputs[\"OpenSearchDomainEndpoint\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "위에서 가져온 정보를 바탕으로 opensearch-py 패키지를 사용하여 OpenSearch 도메인에 접속합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
                "\n",
                "auth = (aos_credentials[\"username\"], aos_credentials[\"password\"])\n",
                "\n",
                "aos_client = OpenSearch(\n",
                "    hosts=[{\"host\": aos_host, \"port\": 443}],\n",
                "    http_auth=auth,\n",
                "    use_ssl=True,\n",
                "    verify_certs=True,\n",
                "    connection_class=RequestsHttpConnection,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "모델 아이디와 인덱스명을 설정하고 이 과정에서 사용할 인덱스가 잘 준비되어 있는지 확인합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_id = \"jK-l048BhWoFUAg8WOdO\"\n",
                "index_name = \"movie_semantic\"\n",
                "\n",
                "count = aos_client.count(index=index_name)\n",
                "print(count)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 검색 함수 정의하기\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 키워드 함수 정의\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def keyword_search(query_text):\n",
                "    query = {\n",
                "        \"size\": 10,\n",
                "        \"query\": {\n",
                "            \"multi_match\": {\n",
                "                \"query\": query_text,\n",
                "                \"fields\": [\"plot\"],\n",
                "            }\n",
                "        },\n",
                "    }\n",
                "\n",
                "    res = aos_client.search(index=index_name, body=query)\n",
                "\n",
                "    query_result = []\n",
                "    for hit in res[\"hits\"][\"hits\"]:\n",
                "        row = [\n",
                "            hit[\"_score\"],\n",
                "            hit[\"_source\"][\"title\"],\n",
                "            hit[\"_source\"][\"plot\"],\n",
                "            hit[\"_source\"][\"genre\"],\n",
                "            hit[\"_source\"][\"rating\"],\n",
                "            hit[\"_source\"][\"main_act\"],\n",
                "        ]\n",
                "        query_result.append(row)\n",
                "\n",
                "    query_result_df = pd.DataFrame(\n",
                "        data=query_result,\n",
                "        columns=[\"_score\", \"title\", \"plot\", \"genre\", \"rating\", \"main_act\"],\n",
                "    )\n",
                "    display(query_result_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 시맨틱 검색 함수 정의\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def semantic_search(query_text):\n",
                "    query = {\n",
                "        \"size\": 10,\n",
                "        \"_source\": {\"excludes\": [\"vector_field\"]},\n",
                "        \"query\": {\n",
                "            \"neural\": {\"vector_field\": {\"query_text\": query_text, \"model_id\": model_id, \"k\": 10}},\n",
                "        },\n",
                "    }\n",
                "\n",
                "    res = aos_client.search(index=index_name, body=query)\n",
                "\n",
                "    query_result = []\n",
                "    for hit in res[\"hits\"][\"hits\"]:\n",
                "        row = [\n",
                "            hit[\"_score\"],\n",
                "            hit[\"_source\"][\"title\"],\n",
                "            hit[\"_source\"][\"plot\"],\n",
                "            hit[\"_source\"][\"genre\"],\n",
                "            hit[\"_source\"][\"rating\"],\n",
                "        ]\n",
                "        query_result.append(row)\n",
                "\n",
                "    query_result_df = pd.DataFrame(\n",
                "        data=query_result, columns=[\"_score\", \"title\", \"plot\", \"genre\", \"rating\"]\n",
                "    )\n",
                "    display(query_result_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 하이브리드 검색 함수 정의\n",
                "\n",
                "아래와 같이 Hybrid 검색 함수를 정의합니다. 중요한 부분은 다음과 같습니다.\n",
                "\n",
                "1. **`query`** 부분에서 **`hybrid`** 쿼리를 사용하여 텍스트 기반 검색과 벡터 기반 검색을 결합합니다.\n",
                "    - **`multi_match`** 쿼리는 **`title`**, **`text`**, **`genre`** 필드에서 **`query_text`**와 일치하는 문서를 찾습니다.\n",
                "    - **`neural`** 쿼리는 **`vector_field`**에 저장된 벡터 데이터와 **`query_text`**를 사용하여 유사도 기반 검색을 수행합니다. **`model_id`**는 사용할 모델을 지정하고, **`k`**는 반환할 최대 문서 수를 지정합니다.\n",
                "2. **`search_pipeline`**은 텍스트 기반 검색과 벡터 기반 검색의 결과를 결합하는 방식을 지정합니다.\n",
                "    - **`normalization-processor`**는 두 검색 결과의 점수를 정규화합니다.\n",
                "    - **`combination`** 부분에서 **`arithmetic_mean`** 기법을 사용하여 두 검색 결과의 점수를 가중 평균합니다. 여기서는 텍스트 기반 검색 결과에 0.3의 가중치를, 벡터 기반 검색 결과에 0.7의 가중치를 부여합니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def hybrid_search(query_text, keyword_weight=0.3, semantic_weight=0.7):\n",
                "    query = {\n",
                "        \"size\": 10,\n",
                "        \"_source\": {\"exclude\": [\"vector_field\"]},\n",
                "        \"query\": {\n",
                "            \"hybrid\": {\n",
                "                \"queries\": [\n",
                "                    {\n",
                "                        \"multi_match\": {\n",
                "                            \"query\": query_text,\n",
                "                            \"fields\": [\"title\", \"plot\", \"genre\", \"main_act\", \"supp_act\"],\n",
                "                        }\n",
                "                    },\n",
                "                    {\n",
                "                        \"neural\": {\n",
                "                            \"vector_field\": {\n",
                "                                \"query_text\": query_text,\n",
                "                                \"model_id\": model_id,\n",
                "                                \"k\": 30,\n",
                "                            }\n",
                "                        }\n",
                "                    },\n",
                "                ]\n",
                "            }\n",
                "        },\n",
                "        \"search_pipeline\": {\n",
                "            \"description\": \"Post processor for hybrid search\",\n",
                "            \"phase_results_processors\": [\n",
                "                {\n",
                "                    \"normalization-processor\": {\n",
                "                        \"normalization\": {\"technique\": \"min_max\"},\n",
                "                        \"combination\": {\n",
                "                            \"technique\": \"arithmetic_mean\",\n",
                "                            \"parameters\": {\"weights\": [keyword_weight, semantic_weight]},\n",
                "                        },\n",
                "                    }\n",
                "                }\n",
                "            ],\n",
                "        },\n",
                "    }\n",
                "\n",
                "    res = aos_client.search(index=index_name, body=query)\n",
                "\n",
                "    query_result = []\n",
                "    for hit in res[\"hits\"][\"hits\"]:\n",
                "        row = [\n",
                "            hit[\"_score\"],\n",
                "            hit[\"_source\"][\"title\"],\n",
                "            hit[\"_source\"][\"plot\"],\n",
                "            hit[\"_source\"][\"genre\"],\n",
                "            hit[\"_source\"][\"rating\"],\n",
                "            hit[\"_source\"][\"main_act\"],\n",
                "        ]\n",
                "        query_result.append(row)\n",
                "\n",
                "    query_result_df = pd.DataFrame(\n",
                "        data=query_result, columns=[\"_score\", \"title\", \"plot\", \"genre\", \"rating\", \"main_act\"]\n",
                "    )\n",
                "    display(query_result_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 검색결과 비교하기\n",
                "\n",
                "이전 단계에서 수행한 키워드 검색, 시맨틱 검색과 동일한 쿼리로 검색하여 결과를 비교해봅니다.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query_text = \"어벤져스와 비슷한 액션 SF 추천해줘\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "keyword_search(query_text, index_name, aos_client)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "semantic_search(query_text, index_name, aos_client, model_id)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hybrid_search(query_text, keyword_weight=0.5, semantic_weight=0.5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Clean Up\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# aos_client.indices.delete(index=index_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "opensearch",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}